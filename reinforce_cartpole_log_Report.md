
# CartPole強化学習実験レポート

**生成日時:** 2025-07-09 09:09:39

## 1. 概要

本レポートは、Yggdrasil Agent Framework を用いて実施されたCartPole環境における強化学習実験の結果をまとめたものである。目的は、REINFORCEアルゴリズムを用いたエージェントの学習状況を評価することである。

## 2. 実験環境

- **フレームワーク:** Yggdrasil Agent Framework
- **学習タスク:** CartPole-v1 環境における強化学習
- **使用アルゴリズム:** REINFORCE
- **評価指標:** エピソードごとの累積報酬、過去100エピソードの平均報酬

## 3. 実験結果

以下に、実施された実験のパラメータと結果を示す。

| 実行日時 | エピソード数 | 学習率 | 割引率 | 過去100エピソード平均報酬 | 環境解決 |
|---|---|---|---|---|---|

| 2025-07-09 05:36:03 | 1000 | 0.001 | 0.99 | 196.99 | Yes |
| 2025-07-09 07:19:18 | 500 | 0.001 | 0.99 | 196.18 | Yes |
| 2025-07-09 07:34:37 | 500 | 0.001 | 0.99 | 195.53 | Yes |
| 2025-07-09 07:37:30 | 500 | 0.001 | 0.99 | 197.10 | Yes |
| 2025-07-09 07:40:04 | 500 | 0.001 | 0.99 | 195.32 | Yes |
| 2025-07-09 07:48:35 | 500 | 0.001 | 0.99 | 195.07 | Yes |
| 2025-07-09 08:01:02 | 500 | 0.001 | 0.99 | 196.97 | Yes |
| 2025-07-09 08:04:11 | 500 | 0.001 | 0.99 | 197.25 | Yes |
| 2025-07-09 08:07:25 | 500 | 0.001 | 0.99 | 196.30 | Yes |
| 2025-07-09 08:10:29 | 500 | 0.001 | 0.99 | 195.95 | Yes |
| 2025-07-09 08:13:33 | 500 | 0.001 | 0.99 | 198.79 | Yes |
| 2025-07-09 08:17:23 | 500 | 0.001 | 0.99 | 196.30 | Yes |
| 2025-07-09 08:20:38 | 500 | 0.001 | 0.99 | 195.29 | Yes |
| 2025-07-09 08:23:36 | 500 | 0.001 | 0.99 | 196.77 | Yes |
| 2025-07-09 08:26:44 | 500 | 0.001 | 0.99 | 195.26 | Yes |
| 2025-07-09 08:29:45 | 500 | 0.001 | 0.99 | 195.30 | Yes |
| 2025-07-09 08:32:35 | 500 | 0.001 | 0.99 | 195.77 | Yes |
| 2025-07-09 08:36:13 | 500 | 0.001 | 0.99 | 195.65 | Yes |
| 2025-07-09 08:39:15 | 500 | 0.001 | 0.99 | 195.18 | Yes |
| 2025-07-09 08:42:18 | 500 | 0.001 | 0.99 | 197.94 | Yes |
| 2025-07-09 08:45:25 | 500 | 0.001 | 0.99 | 196.31 | Yes |
| 2025-07-09 08:48:32 | 500 | 0.001 | 0.99 | 198.55 | Yes |
| 2025-07-09 08:59:58 | 500 | 0.001 | 0.99 | 197.06 | Yes |
| 2025-07-09 09:09:32 | 500 | 0.001 | 0.99 | 195.92 | Yes |

### 考察

- **学習状況:** 最新の実験では、500 エピソードを実行し、過去100エピソードの平均報酬は 195.92 でした。環境は解決済みです。
- **成功:** 環境の解決基準を満たしました。エージェントはCartPole環境で安定してバランスを取ることを学習しました。
- **今後の課題:** さらなる性能向上のためには、報酬設計の見直し、より複雑なポリシーネットワークの検討、または他の強化学習アルゴリズム（例: DQN, A2C）の導入が有効と考えられます。

## 4. 結論

本一連の実験により、REINFORCEアルゴリズムを用いたCartPole環境の学習状況を確認した。今回の結果に基づき、今後はさらなるアルゴリズムの改善や、より複雑な環境への適用を検討することが推奨される。
